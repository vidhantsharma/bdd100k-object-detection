# Docker Compose for BDD100K Object Detection
version: '3.8'

services:
  bdd100k:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: bdd100k-detection
    
    # Increase shared memory for DataLoader workers
    shm_size: '2gb'
    
    # GPU support (modern Docker Compose syntax)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Mount local data directories
    volumes:
      # INPUT DATA (read-only) - Your BDD100K dataset
      - ${BDD100K_DATA_PATH}:/data/mounted:ro
      
      # OUTPUT DATA (read-write) - Results saved to host
      # These folders will be created automatically when outputs are generated
      - ../data:/workspace/data
      
      # Source code
      - ../src:/workspace/src
      - ../config:/workspace/config
      - ../main.py:/workspace/main.py
    
    # Keep container running
    stdin_open: true
    tty: true
    
    # Set working directory
    working_dir: /workspace
    
    # Environment variables
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - PYTHONUNBUFFERED=1
    
    # Optional: expose ports for TensorBoard
    ports:
      - "6006:6006"
